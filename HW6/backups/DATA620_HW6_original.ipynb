{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CUNY Data 620 - Web Analytics, Summer 2020\n",
    "**Group Homework Assignment 6**  \n",
    "**Prof:** Alain Ledon  \n",
    "**Members:** Misha Kollontai, Amber Ferger, Zach Alexander, Subhalaxmi Rout  \n",
    "\n",
    "**Youtube Link:** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "\n",
    "It can be useful to be able to classify new \"test\" documents using already classified \"training\" documents. <br>A common example is using a corpus of labeled spam and ham (non-spam) e-mails to predict whether or not a new document is spam. <br>Here is one example of such data: http://archive.ics.uci.edu/ml/datasets/Spambase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "import csv\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using above mentioned link we will download 2 files i.e \"spambase.data\" and \"spambase.names\".<br> spambase.data file consist of features data and spam data (i.e 1 = spam, 0 = Not spam) and spambase.names file contains different features. We will extract these features from the file and apply them to the dataset to create models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['word_freq_make:',\n",
       " 'word_freq_address:',\n",
       " 'word_freq_all:',\n",
       " 'word_freq_3d:',\n",
       " 'word_freq_our:',\n",
       " 'word_freq_over:',\n",
       " 'word_freq_remove:',\n",
       " 'word_freq_internet:',\n",
       " 'word_freq_order:',\n",
       " 'word_freq_mail:',\n",
       " 'word_freq_receive:',\n",
       " 'word_freq_will:',\n",
       " 'word_freq_people:',\n",
       " 'word_freq_report:',\n",
       " 'word_freq_addresses:',\n",
       " 'word_freq_free:',\n",
       " 'word_freq_business:',\n",
       " 'word_freq_email:',\n",
       " 'word_freq_you:',\n",
       " 'word_freq_credit:',\n",
       " 'word_freq_your:',\n",
       " 'word_freq_font:',\n",
       " 'word_freq_000:',\n",
       " 'word_freq_money:',\n",
       " 'word_freq_hp:',\n",
       " 'word_freq_hpl:',\n",
       " 'word_freq_george:',\n",
       " 'word_freq_650:',\n",
       " 'word_freq_lab:',\n",
       " 'word_freq_labs:',\n",
       " 'word_freq_telnet:',\n",
       " 'word_freq_857:',\n",
       " 'word_freq_data:',\n",
       " 'word_freq_415:',\n",
       " 'word_freq_85:',\n",
       " 'word_freq_technology:',\n",
       " 'word_freq_1999:',\n",
       " 'word_freq_parts:',\n",
       " 'word_freq_pm:',\n",
       " 'word_freq_direct:',\n",
       " 'word_freq_cs:',\n",
       " 'word_freq_meeting:',\n",
       " 'word_freq_original:',\n",
       " 'word_freq_project:',\n",
       " 'word_freq_re:',\n",
       " 'word_freq_edu:',\n",
       " 'word_freq_table:',\n",
       " 'word_freq_conference:',\n",
       " 'char_freq_;:',\n",
       " 'char_freq_(:',\n",
       " 'char_freq_[:',\n",
       " 'char_freq_!:',\n",
       " 'char_freq_$:',\n",
       " 'char_freq_#:',\n",
       " 'capital_run_length_average:',\n",
       " 'capital_run_length_longest:',\n",
       " 'capital_run_length_total:']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract feature from spambase.names file.\n",
    "\n",
    "# created an empty feature list\n",
    "categories = []\n",
    "\n",
    "# open file \n",
    "feature_file = open('spambase.names')\n",
    "# remove '\\n', split the text,  and match with word_freq|char_freq feature \n",
    "for line in feature_file:\n",
    "    if not re.match(r'\\|', line):\n",
    "        line = line.rstrip()\n",
    "        if re.search(r'(word_freq_|char_freq_|capital_run_length_).+', line):   \n",
    "            words = line.split()\n",
    "            categories.append(words[0])\n",
    "\n",
    "categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From above all features 'spam' is not availabe, let add spam in the categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['word_freq_make:', 'word_freq_address:', 'word_freq_all:', 'word_freq_3d:', 'word_freq_our:', 'word_freq_over:', 'word_freq_remove:', 'word_freq_internet:', 'word_freq_order:', 'word_freq_mail:', 'word_freq_receive:', 'word_freq_will:', 'word_freq_people:', 'word_freq_report:', 'word_freq_addresses:', 'word_freq_free:', 'word_freq_business:', 'word_freq_email:', 'word_freq_you:', 'word_freq_credit:', 'word_freq_your:', 'word_freq_font:', 'word_freq_000:', 'word_freq_money:', 'word_freq_hp:', 'word_freq_hpl:', 'word_freq_george:', 'word_freq_650:', 'word_freq_lab:', 'word_freq_labs:', 'word_freq_telnet:', 'word_freq_857:', 'word_freq_data:', 'word_freq_415:', 'word_freq_85:', 'word_freq_technology:', 'word_freq_1999:', 'word_freq_parts:', 'word_freq_pm:', 'word_freq_direct:', 'word_freq_cs:', 'word_freq_meeting:', 'word_freq_original:', 'word_freq_project:', 'word_freq_re:', 'word_freq_edu:', 'word_freq_table:', 'word_freq_conference:', 'char_freq_;:', 'char_freq_(:', 'char_freq_[:', 'char_freq_!:', 'char_freq_$:', 'char_freq_#:', 'capital_run_length_average:', 'capital_run_length_longest:', 'capital_run_length_total:', 'spam']\n"
     ]
    }
   ],
   "source": [
    "categories.append('spam')\n",
    "print(categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'spam' feature is avaialabl ein the categories. Load data from spambase.data file. Here we will get the data and store this in csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the file\n",
    "data_file = open('spambase.data')\n",
    "# remove extra space, split the lines and store in csv file\n",
    "for file in data_file:\n",
    "    space_remove = (line.strip() for line in data_file)\n",
    "    lines = (line.split(\",\") for line in space_remove if line)\n",
    "    with open('spambase.csv', 'w') as out_file:\n",
    "        writer = csv.writer(out_file)\n",
    "        writer.writerow(categories)\n",
    "        writer.writerows(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After generate csv file, read the csv file using read_csv()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of data 4600\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('spambase.csv', sep = ',')\n",
    "print(\"Length of data\", len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spam: 1812\n",
      "Non-spam: 2788\n"
     ]
    }
   ],
   "source": [
    "# Count spam and non-spam\n",
    "count_spam = len(data[data.spam == 1])\n",
    "count_nonspam = len(data[data.spam == 0])\n",
    "\n",
    "print(\"Spam: %d\" %count_spam)\n",
    "print(\"Non-spam: %d\" %count_nonspam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   word_freq_make:  word_freq_address:  word_freq_all:  word_freq_3d:  \\\n",
      "0             0.21                0.28            0.50            0.0   \n",
      "1             0.06                0.00            0.71            0.0   \n",
      "2             0.00                0.00            0.00            0.0   \n",
      "3             0.00                0.00            0.00            0.0   \n",
      "\n",
      "   word_freq_our:  word_freq_over:  word_freq_remove:  word_freq_internet:  \\\n",
      "0            0.14             0.28               0.21                 0.07   \n",
      "1            1.23             0.19               0.19                 0.12   \n",
      "2            0.63             0.00               0.31                 0.63   \n",
      "3            0.63             0.00               0.31                 0.63   \n",
      "\n",
      "   word_freq_order:  word_freq_mail:  ...  char_freq_;:  char_freq_(:  \\\n",
      "0              0.00             0.94  ...          0.00         0.132   \n",
      "1              0.64             0.25  ...          0.01         0.143   \n",
      "2              0.31             0.63  ...          0.00         0.137   \n",
      "3              0.31             0.63  ...          0.00         0.135   \n",
      "\n",
      "   char_freq_[:  char_freq_!:  char_freq_$:  char_freq_#:  \\\n",
      "0           0.0         0.372         0.180         0.048   \n",
      "1           0.0         0.276         0.184         0.010   \n",
      "2           0.0         0.137         0.000         0.000   \n",
      "3           0.0         0.135         0.000         0.000   \n",
      "\n",
      "   capital_run_length_average:  capital_run_length_longest:  \\\n",
      "0                        5.114                          101   \n",
      "1                        9.821                          485   \n",
      "2                        3.537                           40   \n",
      "3                        3.537                           40   \n",
      "\n",
      "   capital_run_length_total:  spam  \n",
      "0                       1028     1  \n",
      "1                       2259     1  \n",
      "2                        191     1  \n",
      "3                        191     1  \n",
      "\n",
      "[4 rows x 58 columns]\n"
     ]
    }
   ],
   "source": [
    "# print first 4 rows of data\n",
    "print(data.head(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data splitting:\n",
    "\n",
    "This table consists of 58 columns, we will devide the dataset in to 2 parts i.e the train and the test set. Train data is 75% of data and test data is 25% of data. We will create two variables input and output, input variable is from word_freq_make to  capital_run_length_total and output variable is spam.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.values[:, 0:57]\n",
    "Y = data.values[:, 57]\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameter test_size is given value 0.25. It means test set will be 25% of the whole dataset and training set will be 75%. Parameter random_state is a pseudo-random number generator state used for random sampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 1: Support Vector machine\n",
    "\n",
    "We will create model Support Vector machine algorithm and will create confusion matrix and the accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 1., 0.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train model\n",
    "\n",
    "from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "svm_model = svm.SVC()\n",
    "svm_model.fit(X_train, Y_train)\n",
    "\n",
    "# Prediction\n",
    "svm_pred = svm_model.predict(X_test)\n",
    "svm_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'accuracy_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-6c565fd3d69a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# find accuracy on the Test Set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msvm_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'accuracy_score' is not defined"
     ]
    }
   ],
   "source": [
    "# find accuracy on the Test Set\n",
    "\n",
    "print(accuracy_score(Y_test, svm_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine Performance Metrics\n",
    "\n",
    "print(confusion_matrix(Y_test, svm_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In support vector machine(SVM) the accuracy of spam messages/emails is 81%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reference: ** "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
