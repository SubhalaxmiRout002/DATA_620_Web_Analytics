{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CUNY Data 620 - Web Analytics, Summer 2020  \n",
    "**Group Project 3**   \n",
    "**Prof:** Alain Ledon  \n",
    "**Members:** Misha Kollontai, Amber Ferger, Zach Alexander, Subhalaxmi Rout  \n",
    "  \n",
    "**YouTube Link**: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "Using any of the three classifiers described in chapter 6 of Natural Language Processing with Python,\n",
    "and any features you can think of, build the best name gender classifier you can. \n",
    "\n",
    "Begin by splitting the Names Corpus into three subsets: 500 words for the test set, 500 words for the devtest set, and the remaining 6900 words for the training set. Then, starting with the example name gender classifier, make incremental improvements. Use the dev-test set to check your progress. Once you are satisfied with your classifier, check its final performance on the test set.\n",
    "\n",
    "\n",
    "How does the performance on the test set compare to the performance on the dev-test set? Is this what\n",
    "you'd expect? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import names\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Data\n",
    "\n",
    "The *names* corpus in the nltk package contains the names and genders of 7,944 individuals. First, we will compile a list of all names with their gender. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2943 male names in the dataset.\n",
      "There are 5001 female names in the dataset.\n"
     ]
    }
   ],
   "source": [
    "males = [(name, 'male') for name in names.words('male.txt')]\n",
    "numMales = len(males)\n",
    "females = [(name, 'female') for name in names.words('female.txt')]\n",
    "numFemales = len(females)\n",
    "\n",
    "print(f'There are {numMales} male names in the dataset.')\n",
    "print(f'There are {numFemales} female names in the dataset.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can combine the lists and shuffle the data so that all names of the same gender are not together. We can confirm that the names are shuffled by looking at the genders of the first 5 individuals. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 names in the dataset:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Cordelie', 'female'),\n",
       " ('Peggie', 'female'),\n",
       " ('Solange', 'female'),\n",
       " ('Rana', 'female'),\n",
       " ('Jessy', 'female')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(123)\n",
    "allNames = males + females\n",
    "random.shuffle(allNames)\n",
    "\n",
    "print('First 5 names in the dataset:')\n",
    "allNames[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Features\n",
    "Next, we'll define a function to create features for our names. The initial features will include:\n",
    "* **last_letter**: The last letter of the given name.\n",
    "* **first_letter**: The first letter of the given name. \n",
    "* **name_length**: The length of the given name.\n",
    "* **num_vowels**: The number of vowels in the given name.\n",
    "* **num_consonants**: The number of consonants in the given name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_features(name):\n",
    "    name = name.lower()\n",
    "    features = {}\n",
    "    features['last_letter'] = name[-1]\n",
    "    features['first_letter'] = name[0]\n",
    "    features['name_length'] = len(name)  \n",
    "    vowels = ['a', 'e', 'i', 'o', 'u']\n",
    "    vowelLength = len([i for i in name if i in vowels])\n",
    "    features['num_vowels'] = vowelLength\n",
    "    features['num_consonants'] = len(name) - vowelLength\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test-Split\n",
    "Now that we've defined our feature function, we can run it on our dataset and split it into training, testing, and dev testing sets. \n",
    "* **Training Set**: This data will be used to train our classifiers and fit the models.\n",
    "* **Dev Test Set**: This data will be used to predict the gender (male or female). It will provide an unbiased evaluation of a model fit on the training dataset. We can use the results of the development set to tune our model. \n",
    "* **Test Set**: This data will be used to compute the accuracy of the final model. Since the model has never seen this data, it will provide an unbiased evaluation of the clasifier.\n",
    "\n",
    "The splits will be in the format of ({features}, gender). We will store the names and genders of the individuals in separate lists for each split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num records - train set:  6944\n",
      "Num records - dev test set:  500\n",
      "Num records - test set:  500\n"
     ]
    }
   ],
   "source": [
    "def tts(featureFunc, nameList):\n",
    "    featureSet = [(featureFunc(n),g) for (n,g) in nameList]\n",
    "    test_set, devtest_set, train_set = featureSet[0:500], featureSet[500:1000], featureSet[1000:] \n",
    "    tsName = nameList[0:500]\n",
    "    dtName = nameList[500:1000]\n",
    "    tName = nameList[1000:]\n",
    "    \n",
    "    return test_set, devtest_set, train_set, tsName, dtName, tName\n",
    "\n",
    "test_set, devtest_set, train_set, tsName, dtName, tName = tts(gender_features, allNames)\n",
    "\n",
    "print('Num records - train set: ', len(train_set))\n",
    "print('Num records - dev test set: ', len(devtest_set))\n",
    "print('Num records - test set: ', len(test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original Classifier - Naive Bayes Classifier\n",
    "Now that we've split our data into training, development, and test sets, we can create a **Naive Bayes Classifier** to predict the gender of the names. In this type of model, each feature gets a say in determining which label should be assigned to a given input value. The prior probability is calculated for each label (male, female), and the contribution from each feature is combined with this probability to arrive at a likelihood estimate for each label.\n",
    "\n",
    "We will measure the accuracy of the model (the percentage of names the classifier predicts correctly) using the development test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.782\n"
     ]
    }
   ],
   "source": [
    "nbClass = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print('Accuracy: ', nltk.classify.accuracy(nbClass, devtest_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also take a look at the most important features used for predicting the gender. For each feature, this tells us the ratio of occurences for each gender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "             last_letter = 'a'            female : male   =     33.3 : 1.0\n",
      "             last_letter = 'k'              male : female =     29.2 : 1.0\n",
      "             last_letter = 'p'              male : female =     18.6 : 1.0\n",
      "             last_letter = 'f'              male : female =     15.2 : 1.0\n",
      "             last_letter = 'v'              male : female =      9.8 : 1.0\n",
      "             last_letter = 'd'              male : female =      9.8 : 1.0\n",
      "             last_letter = 'm'              male : female =      9.2 : 1.0\n",
      "             last_letter = 'o'              male : female =      8.0 : 1.0\n",
      "             last_letter = 'w'              male : female =      8.0 : 1.0\n",
      "             last_letter = 'r'              male : female =      6.7 : 1.0\n",
      "            first_letter = 'w'              male : female =      4.6 : 1.0\n",
      "              num_vowels = 5              female : male   =      4.5 : 1.0\n",
      "             last_letter = 'b'              male : female =      4.4 : 1.0\n",
      "             last_letter = 's'              male : female =      4.3 : 1.0\n",
      "             last_letter = 'g'              male : female =      4.3 : 1.0\n"
     ]
    }
   ],
   "source": [
    "nbClass.show_most_informative_features(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the last letter and number of vowels in the names appear to be the driving factors. \n",
    "\n",
    "We can also generate a list of errors to see which names we've classified improperly. This will help us identify what additional features we should add to make the classification more accurate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of errors: 109\n"
     ]
    }
   ],
   "source": [
    "def pred_calc(nameList, featureFunc):\n",
    "    preds = []\n",
    "    errors = []\n",
    "    for (name,actual) in nameList:\n",
    "        guess = nbClass.classify(featureFunc(name))\n",
    "        preds.append((actual,guess,name))\n",
    "        if guess != actual:\n",
    "            errors.append((actual, guess, name))\n",
    "    \n",
    "    return preds, errors\n",
    "\n",
    "preds, errors = pred_calc(dtName, gender_features)\n",
    "print('Number of errors:', len(errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we sort the errors by the last two characters of the first name, we can see that some combinations occur more frequently in males than females and vice versa. For example, the letters *ie* appear more often in male names and then letters *ly* appear more often in female names. Let's update our feature set to take this into account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('female', 'male', 'Em'),\n",
       " ('female', 'male', 'Talyah'),\n",
       " ('female', 'male', 'Shirah'),\n",
       " ('male', 'female', 'Donal'),\n",
       " ('female', 'male', 'Sam'),\n",
       " ('male', 'female', 'Fabian'),\n",
       " ('female', 'male', 'Sean'),\n",
       " ('male', 'female', 'Coleman'),\n",
       " ('male', 'female', 'Christian'),\n",
       " ('male', 'female', 'Adrian'),\n",
       " ('male', 'female', 'Vaughan'),\n",
       " ('female', 'male', 'Meggan'),\n",
       " ('female', 'male', 'Gay'),\n",
       " ('male', 'female', 'Murray'),\n",
       " ('male', 'female', 'Lawrence'),\n",
       " ('male', 'female', 'Bruce'),\n",
       " ('male', 'female', 'Lawerence'),\n",
       " ('male', 'female', 'Erich'),\n",
       " ('female', 'male', 'Dulcy'),\n",
       " ('male', 'female', 'Randi'),\n",
       " ('male', 'female', 'Lindy'),\n",
       " ('female', 'male', 'Freddy'),\n",
       " ('male', 'female', 'Jessee'),\n",
       " ('male', 'female', 'Mikel'),\n",
       " ('male', 'female', 'Nathaniel'),\n",
       " ('female', 'male', 'Pen'),\n",
       " ('female', 'male', 'Gwen'),\n",
       " ('female', 'male', 'Grier'),\n",
       " ('female', 'male', 'Delores'),\n",
       " ('female', 'male', 'Dew'),\n",
       " ('female', 'male', 'Sukey'),\n",
       " ('male', 'female', 'Carey'),\n",
       " ('female', 'male', 'Sophey'),\n",
       " ('female', 'male', 'Sibley'),\n",
       " ('female', 'male', 'Daffy'),\n",
       " ('male', 'female', 'Rutledge'),\n",
       " ('female', 'male', 'Margo'),\n",
       " ('female', 'male', 'Angy'),\n",
       " ('male', 'female', 'Jean-Christophe'),\n",
       " ('male', 'female', 'Sollie'),\n",
       " ('male', 'female', 'Christie'),\n",
       " ('male', 'female', 'Georgie'),\n",
       " ('male', 'female', 'Bobbie'),\n",
       " ('male', 'female', 'Kermie'),\n",
       " ('male', 'female', 'Dennie'),\n",
       " ('male', 'female', 'Pennie'),\n",
       " ('male', 'female', 'Maurie'),\n",
       " ('male', 'female', 'Rickie'),\n",
       " ('female', 'male', 'Charin'),\n",
       " ('female', 'male', 'Devin'),\n",
       " ('female', 'male', 'Cristin'),\n",
       " ('female', 'male', 'Shir'),\n",
       " ('female', 'male', 'Wandis'),\n",
       " ('female', 'male', 'Maris'),\n",
       " ('male', 'female', 'Thorndike'),\n",
       " ('male', 'female', 'Ricki'),\n",
       " ('female', 'male', 'Tomiko'),\n",
       " ('female', 'male', 'Vicky'),\n",
       " ('male', 'female', 'Gayle'),\n",
       " ('male', 'female', 'Yale'),\n",
       " ('male', 'female', 'Beale'),\n",
       " ('male', 'female', 'Pascale'),\n",
       " ('male', 'female', 'Emile'),\n",
       " ('female', 'male', 'Merrill'),\n",
       " ('female', 'male', 'Joly'),\n",
       " ('female', 'male', 'Hally'),\n",
       " ('female', 'male', 'Vally'),\n",
       " ('female', 'male', 'Holly'),\n",
       " ('male', 'female', 'Baily'),\n",
       " ('male', 'female', 'Guillaume'),\n",
       " ('male', 'female', 'Tome'),\n",
       " ('female', 'male', 'Clemmy'),\n",
       " ('male', 'female', 'Zane'),\n",
       " ('male', 'female', 'Simone'),\n",
       " ('male', 'female', 'Dani'),\n",
       " ('female', 'male', 'Jo-Ann'),\n",
       " ('female', 'male', 'Quinn'),\n",
       " ('female', 'male', 'Melicent'),\n",
       " ('female', 'male', 'Vonny'),\n",
       " ('female', 'male', 'Vinny'),\n",
       " ('female', 'male', 'Penny'),\n",
       " ('female', 'male', 'Rhianon'),\n",
       " ('female', 'male', 'Rhiamon'),\n",
       " ('male', 'female', 'Ferguson'),\n",
       " ('female', 'male', 'Leanor'),\n",
       " ('female', 'male', 'Charlot'),\n",
       " ('male', 'female', 'Eliot'),\n",
       " ('female', 'male', 'Harriot'),\n",
       " ('male', 'female', 'Phillipe'),\n",
       " ('male', 'female', 'Demetre'),\n",
       " ('male', 'female', 'Henri'),\n",
       " ('female', 'male', 'Merl'),\n",
       " ('female', 'male', 'Gert'),\n",
       " ('female', 'male', 'Dory'),\n",
       " ('female', 'male', 'Gerry'),\n",
       " ('male', 'female', 'Maurise'),\n",
       " ('female', 'male', 'Lindsy'),\n",
       " ('male', 'female', 'Juanita'),\n",
       " ('male', 'female', 'Durante'),\n",
       " ('female', 'male', 'Janith'),\n",
       " ('female', 'male', 'Marybeth'),\n",
       " ('female', 'male', 'Helen-Elizabeth'),\n",
       " ('male', 'female', 'Morty'),\n",
       " ('female', 'male', 'Fawn'),\n",
       " ('male', 'female', 'Saxe'),\n",
       " ('female', 'male', 'Jesselyn'),\n",
       " ('female', 'male', 'Marilyn'),\n",
       " ('female', 'male', 'Roselyn'),\n",
       " ('female', 'male', 'Ardys')]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(errors, key=lambda x: x[-1][-2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Set Revamp\n",
    "\n",
    "**Last two letters**: First, let's add in a feature for the last 2 letters of each name. We'll recreate our train, test, and dev test splits and run the Naive Bayes Classifer on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.79\n"
     ]
    }
   ],
   "source": [
    "def gender_features2(name):\n",
    "    name = name.lower()\n",
    "    features = {}\n",
    "    features['last_letter'] = name[-1]\n",
    "    features['first_letter'] = name[0]\n",
    "    features['name_length'] = len(name)    \n",
    "    vowels = ['a', 'e', 'i', 'o', 'u']\n",
    "    vowelLength = len([i for i in name if i in vowels])\n",
    "    features['num_vowels'] = vowelLength\n",
    "    features['num_consonants'] = len(name) - vowelLength\n",
    "    \n",
    "    # add in feature for lsat 2 letters of name\n",
    "    features['last_two_letters'] = name[-2:]\n",
    "\n",
    "    return features\n",
    "\n",
    "test_set, devtest_set, train_set, tsName, dtName, tName = tts(gender_features2, allNames)\n",
    "nbClass2 = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print('Accuracy: ', nltk.classify.accuracy(nbClass2, devtest_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our accuracy went up to 79%! Let's try again with some additional features.\n",
    "\n",
    "**Bouba and Kiki Vowels/Consonants**: Sidhu and Pexman (1) discovered a relationship of Bouba with female first names and Kiki with male first names. We will use a modified version of their findings and define the following new features: \n",
    "* **num_bouba_cons**: Count of the letters *b*, *l*, *m*, and *n*. *(Female names tend to have more of these)*\n",
    "* **num_bouba_vowels**: Count of the letters *u* and *o*. *(Female names tend to have more of these)*\n",
    "* **num_kiki_cons**: Count of the letters *k*, *p*, and *t*. *(Male names tend to have more of these)*\n",
    "* **num_kiki_vowels**: Count of the letters *i* and *e*. *(Male names tend to have more of these)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.794\n"
     ]
    }
   ],
   "source": [
    "# https://arxiv.org/pdf/1606.05467.pdf\n",
    "\n",
    "def gender_features3(name):\n",
    "    name = name.lower()\n",
    "    features = {}\n",
    "    features['last_letter'] = name[-1]\n",
    "    features['first_letter'] = name[0]\n",
    "    features['name_length'] = len(name)    \n",
    "    vowels = ['a', 'e', 'i', 'o', 'u']\n",
    "    vowelLength = len([i for i in name if i in vowels])\n",
    "    features['num_vowels'] = vowelLength\n",
    "    features['num_consonants'] = len(name) - vowelLength\n",
    "    \n",
    "    # add in feature for last 2 letters of name\n",
    "    features['last_two_letters'] = name[-2:]\n",
    "    \n",
    "    # add in bouba & kiki counts\n",
    "    boubaCons = ['b', 'l', 'm', 'n']\n",
    "    boubaVowels = ['u', 'o']\n",
    "    kikiCons = ['k', 'p', 't']\n",
    "    kikiVowels = ['i', 'e']\n",
    "    \n",
    "    bcLength = len([i for i in name if i in boubaCons])\n",
    "    bvLength = len([i for i in name if i in boubaVowels])\n",
    "    kcLength = len([i for i in name if i in kikiCons])\n",
    "    kvLength = len([i for i in name if i in kikiVowels])\n",
    "\n",
    "    features['num_bouba_cons'] = bcLength\n",
    "    features['num_bouba_vowels'] = bvLength\n",
    "    features['num_kiki_cons'] = kcLength\n",
    "    features['num_kiki_vowels'] = kvLength\n",
    "\n",
    "    return features\n",
    "\n",
    "test_set, devtest_set, train_set, tsName, dtName, tName = tts(gender_features3, allNames)\n",
    "nbClass3 = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print('Accuracy: ', nltk.classify.accuracy(nbClass3, devtest_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "We can now evaluate the final model on our test set. First, we'll look at the overall accuracy of each of our subsequent models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MODEL</th>\n",
       "      <th>DEV_ACCURACY</th>\n",
       "      <th>TEST_ACCURACY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>First</td>\n",
       "      <td>0.782</td>\n",
       "      <td>0.772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Second</td>\n",
       "      <td>0.790</td>\n",
       "      <td>0.780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Final</td>\n",
       "      <td>0.794</td>\n",
       "      <td>0.782</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    MODEL  DEV_ACCURACY  TEST_ACCURACY\n",
       "0   First         0.782          0.772\n",
       "1  Second         0.790          0.780\n",
       "2   Final         0.794          0.782"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([['First', nltk.classify.accuracy(nbClass, devtest_set), nltk.classify.accuracy(nbClass, test_set)], \n",
    "             ['Second', nltk.classify.accuracy(nbClass2, devtest_set), nltk.classify.accuracy(nbClass2, test_set)], \n",
    "             ['Final', nltk.classify.accuracy(nbClass3, devtest_set), nltk.classify.accuracy(nbClass3, test_set)]],\n",
    "            columns = ['MODEL', 'DEV_ACCURACY', 'TEST_ACCURACY'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the accuracy on the development and test set increases from the first model to the final model. When looking at each model, we also notice that the accuracy on the test set is lower than on the development set. This is expected, as we tweaked our feature set based on the results of the development set and the test set contains data that the model has never seen before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtPred, dtError = pred_calc(dtName, gender_features3)\n",
    "tsPred, tsError = pred_calc(tsName, gender_features3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources\n",
    "\n",
    "1. D. M. Sidhu and P. M. Pexman. What’s in a name? sound symbolism and gender in first names. PLOS ONE, 10(5):e0126809, 2015.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
