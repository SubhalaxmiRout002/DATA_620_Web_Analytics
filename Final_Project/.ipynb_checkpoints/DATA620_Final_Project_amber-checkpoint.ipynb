{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CUNY Data 620 - Web Analytics, Summer 2020  \n",
    "**Final Project: Twitter Pull**   \n",
    "**Prof:** Alain Ledon  \n",
    "**Members:** Misha Kollontai, Amber Ferger, Zach Alexander, Subhalaxmi Rout "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import warnings\n",
    "import datetime\n",
    "import time\n",
    "import math\n",
    "import GetOldTweets3 as got\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions\n",
    "\n",
    "We'll define the following functions:\n",
    "* **perdelta**: Based on a [stackoverflow](https://stackoverflow.com/questions/10688006/generate-a-list-of-datetimes-between-an-interval) thread, this will be used to generate a list of date ranges for our twitter pull. \n",
    "* **getTweets**: This will be used to pull the tweets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "################ date function\n",
    "def perdelta(start, end, delta):\n",
    "    curr = start\n",
    "    while curr < end:\n",
    "        yield curr\n",
    "        curr += delta\n",
    "        \n",
    "################ get tweets function \n",
    "def getTweets(city, startDate, endDate):\n",
    "    n = 10\n",
    "    tweetCriteria = got.manager.TweetCriteria().setQuerySearch('COVID')\\\n",
    "    .setSince(startDate)\\\n",
    "    .setUntil(endDate)\\\n",
    "    .setMaxTweets(n)\\\n",
    "    .setTopTweets(1)\\\n",
    "    .setNear(city)\n",
    "    \n",
    "    ls = []\n",
    "\n",
    "    for i in range(0,n):\n",
    "        try:\n",
    "            tweet = got.manager.TweetManager.getTweets(tweetCriteria)[i]\n",
    "            ls.append([tweet, city, startDate, endDate])\n",
    "        except:\n",
    "            pass \n",
    "    \n",
    "    return(ls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Twitter Data\n",
    "\n",
    "#### Largest City by State\n",
    "\n",
    "* Read in a list of the top 1000 [cities]([https://public.opendatasoft.com/explore/dataset/1000-largest-us-cities-by-population-with-geographic-coordinates/table/?sort=-rank]) in the US\n",
    "* Select top city by state, extract geocoordinates\n",
    "* Split the geocoordinates data into 2 lists so that we can run on 2 separate machines (there is a max of 15 requests per 15 minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in cities doc, select top city from each \n",
    "# https://stackoverflow.com/questions/50415632/how-to-select-top-n-row-from-each-group-after-group-by-in-pandas\n",
    "allData = pd.read_csv('largeCities.csv', delimiter=';')\n",
    "final_cities = allData.sort_values(by = ['State', 'Population'], ascending=False).groupby(['State'], sort=False).head(1)\n",
    "coords = final_cities['Coordinates'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the coordinates into 2 lists\n",
    "mid = math.floor(len(coords)/2)\n",
    "coords1 = coords[0:mid]\n",
    "coords2 = coords[mid:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Date Ranges\n",
    "Next, we'll generate date ranges for pull. Each range will represent 2 weeks, defined as Sunday - Saturday. The total span of the analysis will go from **3/8/2020** to **7/11/2020**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dates = []\n",
    "for result in perdelta(datetime.date(2020, 3, 8), datetime.date(2020, 7, 6), datetime.timedelta(days=14)):  \n",
    "    nextWk = result + datetime.timedelta(days=6)\n",
    "    startDt = result.strftime(\"%Y-%m-%d\")\n",
    "    endDt = nextWk.strftime(\"%Y-%m-%d\")   \n",
    "    all_dates.append((startDt,endDt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41.1399814,-104.8202462\n",
      "43.0389025,-87.9064736\n"
     ]
    }
   ],
   "source": [
    "finalList = []\n",
    "test = coords[0:2]\n",
    "\n",
    "for c in test:\n",
    "    print(c)\n",
    "    for d in all_dates:\n",
    "        ls = getTweets(c,d[0],d[1])\n",
    "        finalList.append(ls)\n",
    "        \n",
    "compiledLs = []\n",
    "\n",
    "for i in finalList:\n",
    "    for j in i:\n",
    "        compiledLs.append([j[1], j[2], j[3], j[0].text, j[0].hashtags])\n",
    "\n",
    "df = pd.DataFrame(compiledLs, columns = ['COORDS', 'WEEK_START', 'WEEK_END', 'TEXT', 'HASHTAGS']) \n",
    "df.to_csv('test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compiledLs = []\n",
    "\n",
    "#for i in finalList:\n",
    "#    for j in i:\n",
    "#        compiledLs.append([j[1], j[2], j[3], j[0].text, j[0].hashtags])\n",
    "\n",
    "#df = pd.DataFrame(compiledLs, columns = ['COORDS', 'WEEK_START', 'WEEK_END', 'TEXT', 'HASHTAGS']) \n",
    "#df.to_csv('test_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pull Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cycle through all cities\n",
    "finalList = []\n",
    "\n",
    "for i,c in enumerate(coords1):\n",
    "    if ((i+1) % 2 != 0) and (i != 0):\n",
    "        time.sleep(930) # wait 15 min, 30 sec before continuing\n",
    "    for d in all_dates:\n",
    "        ls = getTweets(c,d[0],d[1])\n",
    "        finalList.append(ls)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
